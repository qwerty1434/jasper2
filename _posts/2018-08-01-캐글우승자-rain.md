---
layout: post
current: post
cover:  assets/images/locked.jpg
navigation: True
title: 캐글우승자-rain
date: 2017-07-27 06:00:00
tags: [Getting started]
class: post-template
subclass: 'post tag-getting-started'
author: qwerty1434
---
캐글의 "How much does it rain?II" 대회에서 우승한 코드를 리뷰해 보려 합니다
대회: https://www.kaggle.com/c/how-much-did-it-rain-ii
우승자 설명: http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/
코드: https://github.com/simaaron/kaggle-Rain

preprocessing->augmentation-train,test,valid->train network->prediction 순서입니다

1.preproessing - 최대한 적은 데이터 변환과정을 거쳤다
2.augmentation - 
가장 신기한 방식이었다.
가운데 빵꾸를 위 or 아래의 값으로 채우는 방식인데 이러한 과정을 여러번 반복한다(여기서는 아마 60번)
그렇게 되면 반복할 때마다 같은 빈칸이라도 어떤때는 위의 값으로 채워지고 어떤때는 아래값으로 채워지기도 할 것이다
이러한 과정을 통해 서로 다른 60개의 데이터가 만들어 지고 이를 학습에 이용한다
비슷하지만 NA값이 다르게 채워진 60개의 데이터로 학습하게 된다
공모전에 적용해 볼려 했는데 1. 데이터가 적은경우  2.연속해서 NA가 많은 경우  의 문제때문에 좋은 방법이 아니라 판단했고 포기했다

(학습과정에서 순서가 없어서 빈칸이 아닌 데이터는 60번 들어가고 빈칸인 데이터는 위의 값으로 30번(확률상) 아래의 값으로 30번 학습하는건가)
(데이터들이 학습과정에서 순서가 없다고 한다면 NA가 아닌 확실한 값의 경우 60번 학습되게 되고 빈칸의 경우 확률상 자기 위의 값으로 30번, 
자기 아래 값으로 30번 학습이 될 거니 NA가 아닌 데이터에 대한 가중치가 더 커지는건가?)

3.network - 
NN_architectures.py에서 만든 모델을 NNregression_v2.py에서 fit시킨다(v1이 왜 안되는지는 나도잘 모르겠음)
4.NN_predictor_v2.py를 통해 예측
